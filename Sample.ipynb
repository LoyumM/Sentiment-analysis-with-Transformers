{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/data)\n",
    "\n",
    "[sentiment-analysis-on-movie-reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.competition_download_file('sentiment-analysis-on-movie-reviews','test.tsv.zip', path='.data/')\n",
    "api.competition_download_file('sentiment-analysis-on-movie-reviews','train.tsv.zip',path='.data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/test.tsv.zip','r') as f:\n",
    "    f.extractall('data/')\n",
    "    \n",
    "with zipfile.ZipFile('data/train.tsv.zip','r') as f:\n",
    "    f.extractall('data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same sentence is copied multiple times, and all copies or duplicates has the same sentence id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataframe is 156060\n",
      "And the number of unique sentences are 8529\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of the dataframe is {len(df)}\")\n",
    "print(f\"And the number of unique sentences are {len(df['SentenceId'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "- 0 - negative\n",
    "- 1 - somewhat negative\n",
    "- 2 - neutral\n",
    "- 3 - somewhat positive\n",
    "- 4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(df['Phrase'].tolist(), max_length=seq_len,truncation = True, padding='max_length', add_special_tokens=True, return_tensors='np') # the special tokens are specific to BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101, 22572, 12148, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving it as a numpy binary file\n",
    "import numpy as np\n",
    "with open('data/movie-xids.npy','wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "with open('data/movie-xmask.npy','wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((num_samples, arr.max()+1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[np.arange(num_samples), arr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/movies_labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/movie-xids.npy','rb') as f:\n",
    "    Xids = np.load(f, allow_pickle=True)\n",
    "with open('data/movie-xmask.npy','rb') as f:\n",
    "    Xmask = np.load(f, allow_pickle=True)\n",
    "with open('data/movies_labels.npy','rb') as f:\n",
    "    labels = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {input_ids, attention_mask}, outputs \n",
    "\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int((Xids.shape[0]/batch_size)*split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "vals_ds = dataset.skip(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Loyumba\\AppData\\Local\\Temp\\ipykernel_14492\\2438375560.py:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_ds, 'train')\n",
    "tf.data.experimental.save(vals_ds, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec == vals_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Loyumba\\AppData\\Local\\Temp\\ipykernel_14492\\2337151686.py:1: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.experimental.load('train', element_spec=train_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD AND TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two inputs\n",
    "input_ids = tf.keras.layers.Input(shape=512,name='input_ids',dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,),name='attention_mask',dtype='int32')\n",
    "\n",
    "#transformers\n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]\n",
    "\n",
    "#classifier_head\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='ouputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " ouputs (Dense)                 (None, 5)            5125        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 109,102,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert is the second layer and because we dont want to train a model\n",
    "# with over 100 million params, we will be setting trainable = False \n",
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " ouputs (Dense)                 (None, 5)            5125        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 792,581\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy\n",
    "# importing the legacy version of adam optimizer \n",
    "# because decay has been depriciated in newer tf versions\n",
    "optimizer = legacy.Adam(learning_rate=5e-5, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int32, name=None),\n",
    "                 'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)},\n",
    "                tf.TensorSpec(shape=(16,5), dtype=tf.float64, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.experimental.load('train', element_spec=element_spec)\n",
    "val_ds = tf.data.experimental.load('val',element_spec=element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4230/8778 [=============>................] - ETA: 24:09:32 - loss: 1.1266 - accuracy: 0.5538"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds, \n",
    "    validation_data = val_ds,\n",
    "    epochs = 5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
